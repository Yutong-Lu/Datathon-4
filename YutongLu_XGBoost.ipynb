{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yutong-Lu/Datathon-4/blob/main/YutongLu_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c315e2e6",
      "metadata": {
        "id": "c315e2e6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as  sns\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import CategoricalNB, GaussianNB, MultinomialNB\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import RocCurveDisplay, roc_curve, accuracy_score, confusion_matrix, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from category_encoders import OneHotEncoder, TargetEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad49cd70",
      "metadata": {
        "id": "ad49cd70",
        "outputId": "220693bf-b8df-4328-a9cc-1cac84db0b07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>hospital_id</th>\n",
              "      <th>hospital_death</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>elective_surgery</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>...</th>\n",
              "      <th>aids</th>\n",
              "      <th>cirrhosis</th>\n",
              "      <th>diabetes_mellitus</th>\n",
              "      <th>hepatic_failure</th>\n",
              "      <th>immunosuppression</th>\n",
              "      <th>leukemia</th>\n",
              "      <th>lymphoma</th>\n",
              "      <th>solid_tumor_with_metastasis</th>\n",
              "      <th>apache_3j_bodysystem</th>\n",
              "      <th>apache_2_bodysystem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66154</td>\n",
              "      <td>25312</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>22.73</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>180.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sepsis</td>\n",
              "      <td>Cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>114252</td>\n",
              "      <td>59342</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>27.42</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>160.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Respiratory</td>\n",
              "      <td>Respiratory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119783</td>\n",
              "      <td>50777</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>31.95</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>172.7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Metabolic</td>\n",
              "      <td>Metabolic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79267</td>\n",
              "      <td>46918</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>22.64</td>\n",
              "      <td>1</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>F</td>\n",
              "      <td>165.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Cardiovascular</td>\n",
              "      <td>Cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92056</td>\n",
              "      <td>34377</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>M</td>\n",
              "      <td>188.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Trauma</td>\n",
              "      <td>Trauma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 186 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi  \\\n",
              "0         66154       25312          118               0  68.0  22.73   \n",
              "1        114252       59342           81               0  77.0  27.42   \n",
              "2        119783       50777          118               0  25.0  31.95   \n",
              "3         79267       46918          118               0  81.0  22.64   \n",
              "4         92056       34377           33               0  19.0    NaN   \n",
              "\n",
              "   elective_surgery  ethnicity gender  height  ... aids cirrhosis  \\\n",
              "0                 0  Caucasian      M   180.3  ...  0.0       0.0   \n",
              "1                 0  Caucasian      F   160.0  ...  0.0       0.0   \n",
              "2                 0  Caucasian      F   172.7  ...  0.0       0.0   \n",
              "3                 1  Caucasian      F   165.1  ...  0.0       0.0   \n",
              "4                 0  Caucasian      M   188.0  ...  0.0       0.0   \n",
              "\n",
              "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
              "0                1.0             0.0               0.0       0.0       0.0   \n",
              "1                1.0             0.0               0.0       0.0       0.0   \n",
              "2                0.0             0.0               0.0       0.0       0.0   \n",
              "3                0.0             0.0               0.0       0.0       0.0   \n",
              "4                0.0             0.0               0.0       0.0       0.0   \n",
              "\n",
              "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \n",
              "0                          0.0                Sepsis       Cardiovascular  \n",
              "1                          0.0           Respiratory          Respiratory  \n",
              "2                          0.0             Metabolic            Metabolic  \n",
              "3                          0.0        Cardiovascular       Cardiovascular  \n",
              "4                          0.0                Trauma               Trauma  \n",
              "\n",
              "[5 rows x 186 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('datathon4.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "576648a3",
      "metadata": {
        "id": "576648a3",
        "outputId": "0e703dd1-c99a-4192-b659-549ef4f9b390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(91713, 186)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab09df8",
      "metadata": {
        "id": "bab09df8",
        "outputId": "ade426ad-789f-4509-ae63-0515bc1b187e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "encounter_id                      0\n",
              "patient_id                        0\n",
              "hospital_id                       0\n",
              "hospital_death                    0\n",
              "age                            4228\n",
              "                               ... \n",
              "leukemia                        715\n",
              "lymphoma                        715\n",
              "solid_tumor_with_metastasis     715\n",
              "apache_3j_bodysystem           1662\n",
              "apache_2_bodysystem            1662\n",
              "Length: 186, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count the number of missing values (NaN or None) in each column of the 'data' DataFrame\n",
        "missing_value_counts = data.isnull().sum()\n",
        "missing_value_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4b480d",
      "metadata": {
        "id": "7d4b480d",
        "outputId": "5c6ca0b1-defa-467f-fe1a-6e45e6538a6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# all readmission status is 0, also redundant with icu_admit_type\n",
        "(data['readmission_status'] == 1).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3440353e",
      "metadata": {
        "id": "3440353e",
        "outputId": "4c5a9959-3fa1-42df-ae1d-f9efa228dbda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7947"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(data['apache_4a_hospital_death_prob'].isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e87c9d8",
      "metadata": {
        "id": "4e87c9d8"
      },
      "outputs": [],
      "source": [
        "# Create a subset with manual feature selection\n",
        "df = data.drop(['encounter_id', 'patient_id', 'hospital_id','icu_id',\n",
        "               'apache_3j_bodysystem', 'apache_2_bodysystem', 'readmission_status',\n",
        "                'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ea7729",
      "metadata": {
        "id": "81ea7729",
        "outputId": "3ab0968e-a047-41b8-ecd3-53ed4e60fd4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Caucasian' nan 'Hispanic' 'African American' 'Asian' 'Native American'\n",
            " 'Other/Unknown']\n",
            "['M' 'F' nan]\n",
            "['Floor' 'Emergency Department' 'Operating Room' nan 'Direct Admit'\n",
            " 'Other Hospital' 'Other ICU' 'ICU to SDU' 'Recovery Room'\n",
            " 'Chest Pain Center' 'Step-Down Unit (SDU)' 'Acute Care/Floor' 'PACU'\n",
            " 'Observation' 'ICU' 'Other']\n",
            "['Floor' 'Accident & Emergency' 'Operating Room / Recovery'\n",
            " 'Other Hospital' 'Other ICU' nan]\n",
            "['admit' 'readmit' 'transfer']\n",
            "['CTICU' 'Med-Surg ICU' 'CCU-CTICU' 'Neuro ICU' 'MICU' 'SICU'\n",
            " 'Cardiac ICU' 'CSICU']\n"
          ]
        }
      ],
      "source": [
        "# Define the column that will be used as the target for modeling or analysis\n",
        "target_column = 'hospital_death'\n",
        "\n",
        "# List of columns that contain categorical data\n",
        "categorical_columns = ['ethnicity', 'gender','hospital_admit_source', 'icu_admit_source',\n",
        "                       'icu_stay_type', 'icu_type']\n",
        "\n",
        "# List of columns that contain numerical data (excluding categorical columns and the target column)\n",
        "numerical_columns = [c for c in df.columns if c not in categorical_columns and c != target_column]\n",
        "\n",
        "for c in categorical_columns:\n",
        "    print(df[c].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b454d6a9",
      "metadata": {
        "id": "b454d6a9"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into 80% training and 20% testing\n",
        "train = df.sample(frac=0.8, random_state=10)\n",
        "test = df.drop(train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2523b95b",
      "metadata": {
        "id": "2523b95b",
        "outputId": "1076e137-5865-421a-cba1-3f4f3b003697"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m imputer \u001b[38;5;241m=\u001b[39m IterativeImputer(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Use the imputer to impute the null values in the specified columns\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_imputed[numerical_columns] \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(train_imputed[numerical_columns])\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:761\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[1;32m    758\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[1;32m    759\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[1;32m    760\u001b[0m     )\n\u001b[0;32m--> 761\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impute_one_feature(\n\u001b[1;32m    762\u001b[0m         Xt,\n\u001b[1;32m    763\u001b[0m         mask_missing_values,\n\u001b[1;32m    764\u001b[0m         feat_idx,\n\u001b[1;32m    765\u001b[0m         neighbor_feat_idx,\n\u001b[1;32m    766\u001b[0m         estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    767\u001b[0m         fit_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    768\u001b[0m     )\n\u001b[1;32m    769\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[1;32m    770\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[1;32m    771\u001b[0m     )\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:444\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    440\u001b[0m     imputed_values[inrange_mask] \u001b[38;5;241m=\u001b[39m truncated_normal\u001b[38;5;241m.\u001b[39mrvs(\n\u001b[1;32m    441\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state_\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     imputed_values \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    445\u001b[0m     imputed_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\n\u001b[1;32m    446\u001b[0m         imputed_values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_value[feat_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_value[feat_idx]\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# update the feature\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_bayes.py:393\u001b[0m, in \u001b[0;36mBayesianRidge.predict\u001b[0;34m(self, X, return_std)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_intercept(X_offset_, y_offset_, X_scale_)\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    394\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    In addition to the mean of the predictive distribution, also its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m        Standard deviation of predictive distribution of query points.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     y_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Imputation\n",
        "\n",
        "# Create a copy of the dataset to use for imputation\n",
        "train_imputed = train.copy()\n",
        "\n",
        "# Imputation\n",
        "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
        "\n",
        "# Use the imputer to impute the null values in the specified columns\n",
        "train_imputed[numerical_columns] = imputer.fit_transform(train_imputed[numerical_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb66eda6",
      "metadata": {
        "id": "eb66eda6"
      },
      "outputs": [],
      "source": [
        "# Initializing the ColumnTransformer\n",
        "# One-hot encoding is applied to all categorical columns except 'country'\n",
        "# Target encoding is applied specifically to the 'country' column\n",
        "ct = ColumnTransformer([\n",
        "    ('one_hot_encoder', OneHotEncoder(), [c for c in categorical_columns if c != 'ethnicity']),\n",
        "    ('target_encoder', TargetEncoder(), ['ethnicity'])\n",
        "], remainder='passthrough')  # Any other columns not specified will be passed through without any transformation\n",
        "\n",
        "# Initializing the Gradient Boosting Classifier with specified parameters\n",
        "random_forest = HistGradientBoostingClassifier(max_iter = 100, learning_rate=1.0, max_depth=1)\n",
        "\n",
        "# Creating a Pipeline:\n",
        "# First, the data goes through the specified column transformations (ct)\n",
        "# Then, the transformed data is used to train or predict using the Gradient Boosting model\n",
        "model = Pipeline([\n",
        "    ('pre_process', ct),        # Pre-processing step: Applying column transformations\n",
        "    ('hist_boost', random_forest) # Training/prediction step: Using Gradient Boosting\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c33a72",
      "metadata": {
        "id": "c0c33a72",
        "outputId": "8ae3c3a8-99f0-4dbc-9e03-33885bf104bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.913645532355667"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training the Gradient Boosting model on the training dataset\n",
        "model = model.fit(train.drop('hospital_death', axis=1),\n",
        "                  train['hospital_death'])\n",
        "\n",
        "# Predicting on the training dataset and computing the accuracy\n",
        "Y_pred = model.predict(train.drop('hospital_death', axis=1))\n",
        "accuracy_score(train['hospital_death'], Y_pred)\n",
        "\n",
        "# Predicting on the test dataset and computing the accuracy\n",
        "Y_pred = model.predict(test.drop('hospital_death', axis=1))\n",
        "accuracy_score(test['hospital_death'], Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2766c574",
      "metadata": {
        "id": "2766c574"
      },
      "outputs": [],
      "source": [
        "# Defining the hyperparameters to be tuned using GridSearchCV\n",
        "param_dist = {\n",
        "    \"hist_boost__max_iter\" : [100, 200],\n",
        "    \"hist_boost__max_depth\" : [1, 3, 5],\n",
        "    \"hist_boost__min_samples_leaf\" : [25, 50],\n",
        "    \"hist_boost__learning_rate\" : [.1,  .2]\n",
        "}\n",
        "\n",
        "# Using StratifiedKFold for cross-validation, ensuring each fold has the same proportion of observations with each target value\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Setting up the GridSearchCV to find the best hyperparameters for the Gradient Boosting model\n",
        "random_search = GridSearchCV(model, param_grid=param_dist, cv=skf)\n",
        "\n",
        "# Fitting the GridSearchCV on the training data\n",
        "random_search.fit(train.drop('hospital_death', axis=1),\n",
        "                  train['hospital_death'])\n",
        "\n",
        "# Storing and displaying the results of the grid search\n",
        "results = pd.DataFrame(random_search.cv_results_)\n",
        "results[results['rank_test_score'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a238a1c",
      "metadata": {
        "id": "9a238a1c"
      },
      "outputs": [],
      "source": [
        "# Updating the model's parameters with the best ones found from GridSearchCV\n",
        "model = model.set_params(**random_search.best_params_)\n",
        "\n",
        "# Retraining the model with the best parameters on the training dataset\n",
        "model = model.fit(train.drop('hospital_death', axis=1), train['hospital_death'])\n",
        "\n",
        "# Predicting on the training dataset and computing the accuracy\n",
        "Y_pred = model.predict(train.drop('hospital_death', axis=1))\n",
        "accuracy_score(train['hospital_death'], Y_pred)\n",
        "\n",
        "# Predicting on the test dataset and computing the accuracy\n",
        "Y_pred = model.predict(test.drop('hospital_death', axis=1))\n",
        "accuracy_score(test['hospital_death'], Y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}