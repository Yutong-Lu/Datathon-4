{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c315e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as  sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB, MultinomialNB\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, accuracy_score, confusion_matrix, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad49cd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>...</th>\n",
       "      <th>aids</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79267</td>\n",
       "      <td>46918</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92056</td>\n",
       "      <td>34377</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi  \\\n",
       "0         66154       25312          118               0  68.0  22.73   \n",
       "1        114252       59342           81               0  77.0  27.42   \n",
       "2        119783       50777          118               0  25.0  31.95   \n",
       "3         79267       46918          118               0  81.0  22.64   \n",
       "4         92056       34377           33               0  19.0    NaN   \n",
       "\n",
       "   elective_surgery  ethnicity gender  height  ... aids cirrhosis  \\\n",
       "0                 0  Caucasian      M   180.3  ...  0.0       0.0   \n",
       "1                 0  Caucasian      F   160.0  ...  0.0       0.0   \n",
       "2                 0  Caucasian      F   172.7  ...  0.0       0.0   \n",
       "3                 1  Caucasian      F   165.1  ...  0.0       0.0   \n",
       "4                 0  Caucasian      M   188.0  ...  0.0       0.0   \n",
       "\n",
       "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
       "0                1.0             0.0               0.0       0.0       0.0   \n",
       "1                1.0             0.0               0.0       0.0       0.0   \n",
       "2                0.0             0.0               0.0       0.0       0.0   \n",
       "3                0.0             0.0               0.0       0.0       0.0   \n",
       "4                0.0             0.0               0.0       0.0       0.0   \n",
       "\n",
       "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \n",
       "0                          0.0                Sepsis       Cardiovascular  \n",
       "1                          0.0           Respiratory          Respiratory  \n",
       "2                          0.0             Metabolic            Metabolic  \n",
       "3                          0.0        Cardiovascular       Cardiovascular  \n",
       "4                          0.0                Trauma               Trauma  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datathon4.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576648a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91713, 186)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab09df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id                      0\n",
       "patient_id                        0\n",
       "hospital_id                       0\n",
       "hospital_death                    0\n",
       "age                            4228\n",
       "                               ... \n",
       "leukemia                        715\n",
       "lymphoma                        715\n",
       "solid_tumor_with_metastasis     715\n",
       "apache_3j_bodysystem           1662\n",
       "apache_2_bodysystem            1662\n",
       "Length: 186, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of missing values (NaN or None) in each column of the 'data' DataFrame\n",
    "missing_value_counts = data.isnull().sum()\n",
    "missing_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4b480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all readmission status is 0, also redundant with icu_admit_type\n",
    "(data['readmission_status'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3440353e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['apache_4a_hospital_death_prob'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e87c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset with manual feature selection\n",
    "df = data.drop(['encounter_id', 'patient_id', 'hospital_id','icu_id',\n",
    "               'apache_3j_bodysystem', 'apache_2_bodysystem', 'readmission_status', \n",
    "                'apache_4a_icu_death_prob', 'apache_4a_hospital_death_prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ea7729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caucasian' nan 'Hispanic' 'African American' 'Asian' 'Native American'\n",
      " 'Other/Unknown']\n",
      "['M' 'F' nan]\n",
      "['Floor' 'Emergency Department' 'Operating Room' nan 'Direct Admit'\n",
      " 'Other Hospital' 'Other ICU' 'ICU to SDU' 'Recovery Room'\n",
      " 'Chest Pain Center' 'Step-Down Unit (SDU)' 'Acute Care/Floor' 'PACU'\n",
      " 'Observation' 'ICU' 'Other']\n",
      "['Floor' 'Accident & Emergency' 'Operating Room / Recovery'\n",
      " 'Other Hospital' 'Other ICU' nan]\n",
      "['admit' 'readmit' 'transfer']\n",
      "['CTICU' 'Med-Surg ICU' 'CCU-CTICU' 'Neuro ICU' 'MICU' 'SICU'\n",
      " 'Cardiac ICU' 'CSICU']\n"
     ]
    }
   ],
   "source": [
    "# Define the column that will be used as the target for modeling or analysis\n",
    "target_column = 'hospital_death'\n",
    "\n",
    "# List of columns that contain categorical data\n",
    "categorical_columns = ['ethnicity', 'gender','hospital_admit_source', 'icu_admit_source', \n",
    "                       'icu_stay_type', 'icu_type']\n",
    "\n",
    "# List of columns that contain numerical data (excluding categorical columns and the target column)\n",
    "numerical_columns = [c for c in df.columns if c not in categorical_columns and c != target_column]\n",
    "\n",
    "for c in categorical_columns:\n",
    "    print(df[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b454d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into 80% training and 20% testing\n",
    "train = df.sample(frac=0.8, random_state=10)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2523b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "\n",
    "# Create a copy of the dataset to use for imputation\n",
    "# train_imputed = train.copy()\n",
    "\n",
    "# Imputation\n",
    "# imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "\n",
    "# Use the imputer to impute the null values in the specified columns\n",
    "# train_imputed[numerical_columns] = imputer.fit_transform(train_imputed[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb66eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ColumnTransformer\n",
    "# One-hot encoding is applied to all categorical columns except 'country'\n",
    "# Target encoding is applied specifically to the 'country' column\n",
    "ct = ColumnTransformer([\n",
    "    ('one_hot_encoder', OneHotEncoder(), [c for c in categorical_columns if c != 'ethnicity']),\n",
    "    ('target_encoder', TargetEncoder(), ['ethnicity'])\n",
    "], remainder='passthrough')  # Any other columns not specified will be passed through without any transformation\n",
    "\n",
    "# Initializing the Gradient Boosting Classifier with specified parameters\n",
    "random_forest = HistGradientBoostingClassifier(max_iter = 100, learning_rate=1.0, max_depth=1)\n",
    "\n",
    "# Creating a Pipeline:\n",
    "# First, the data goes through the specified column transformations (ct)\n",
    "# Then, the transformed data is used to train or predict using the Gradient Boosting model\n",
    "model = Pipeline([\n",
    "    ('pre_process', ct),        # Pre-processing step: Applying column transformations\n",
    "    ('hist_boost', random_forest) # Training/prediction step: Using Gradient Boosting\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c33a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164258845336095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Gradient Boosting model on the training dataset\n",
    "model = model.fit(train.drop('hospital_death', axis=1), \n",
    "                  train['hospital_death'])\n",
    "\n",
    "# Predicting on the training dataset and computing the accuracy\n",
    "Y_pred = model.predict(train.drop('hospital_death', axis=1))\n",
    "accuracy_score(train['hospital_death'], Y_pred)\n",
    "\n",
    "# Predicting on the test dataset and computing the accuracy\n",
    "Y_pred = model.predict(test.drop('hospital_death', axis=1))\n",
    "accuracy_score(test['hospital_death'], Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2766c574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_hist_boost__learning_rate</th>\n",
       "      <th>param_hist_boost__max_depth</th>\n",
       "      <th>param_hist_boost__max_iter</th>\n",
       "      <th>param_hist_boost__min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.400269</td>\n",
       "      <td>0.524885</td>\n",
       "      <td>0.036751</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>{'hist_boost__learning_rate': 0.1, 'hist_boost...</td>\n",
       "      <td>0.931171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930489</td>\n",
       "      <td>0.933352</td>\n",
       "      <td>0.933352</td>\n",
       "      <td>0.931171</td>\n",
       "      <td>0.934306</td>\n",
       "      <td>0.933215</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.932016</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11       4.400269      0.524885         0.036751        0.005306   \n",
       "\n",
       "   param_hist_boost__learning_rate param_hist_boost__max_depth  \\\n",
       "11                             0.1                           5   \n",
       "\n",
       "   param_hist_boost__max_iter param_hist_boost__min_samples_leaf  \\\n",
       "11                        200                                 50   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "11  {'hist_boost__learning_rate': 0.1, 'hist_boost...           0.931171  ...   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "11           0.930489           0.933352           0.933352   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "11           0.931171           0.934306           0.933215   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11           0.931034         0.932016        0.001323                1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the hyperparameters to be tuned using GridSearchCV\n",
    "param_dist = {\n",
    "    \"hist_boost__max_iter\" : [100, 200],\n",
    "    \"hist_boost__max_depth\" : [1, 3, 5],\n",
    "    \"hist_boost__min_samples_leaf\" : [25, 50],\n",
    "    \"hist_boost__learning_rate\" : [.1,  .2]\n",
    "}\n",
    "\n",
    "# Using StratifiedKFold for cross-validation, ensuring each fold has the same proportion of observations with each target value\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Setting up the GridSearchCV to find the best hyperparameters for the Gradient Boosting model\n",
    "random_search = GridSearchCV(model, param_grid=param_dist, cv=skf)\n",
    "\n",
    "# Fitting the GridSearchCV on the training data\n",
    "random_search.fit(train.drop('hospital_death', axis=1), \n",
    "                  train['hospital_death'])\n",
    "\n",
    "# Storing and displaying the results of the grid search\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results[results['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a238a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9320176634138363"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating the model's parameters with the best ones found from GridSearchCV\n",
    "model = model.set_params(**random_search.best_params_)\n",
    "\n",
    "# Retraining the model with the best parameters on the training dataset\n",
    "model = model.fit(train.drop('hospital_death', axis=1), train['hospital_death'])\n",
    "\n",
    "# Predicting on the training dataset and computing the accuracy\n",
    "Y_pred = model.predict(train.drop('hospital_death', axis=1))\n",
    "accuracy_score(train['hospital_death'], Y_pred)\n",
    "\n",
    "# Predicting on the test dataset and computing the accuracy\n",
    "Y_pred = model.predict(test.drop('hospital_death', axis=1))\n",
    "accuracy_score(test['hospital_death'], Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
